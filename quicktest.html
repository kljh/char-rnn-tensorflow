<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Recurrent Neural Network</title>
<script src="save/js/model_data_layer2_n56.js"></script>
<script src="quicktest.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

<style>
body {
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
h1, h2, h3, h4, h5, h6 {
    font-family: "Crete Round", Cambria, Georgia, serif;
    font-weight: normal;
    /*color: #363B40;*/
    clear: both;
}

h1 {
    font-size: 2.25rem;
    line-height: 2.5rem;
    margin-bottom: 1.5rem;
    letter-spacing: -1.5px;
}

h2 {
    font-size: 1.5rem;
    line-height: 1.875rem;
    margin-bottom: 1.5rem;
    letter-spacing: -1px;
}

h3 {
    font-size: 1.125rem;
    line-height: 1.5rem;
    margin-bottom: 1.5rem;
    letter-spacing: -1px;
}

label { display: inline-block; width: 180px; text-align: left; }

em { font-weight: bold; }

</style>
<script>
$(document).ready( function () {
	/*
	$.get("concrete_data.csv")
	.done(onModelDataLoaded)
	.fail(err => alert("failed to load data CSV. "+err));
	*/

	onModelDataLoaded();
	onInputChars(document.getElementById("text").value);

	$("#text").keyup(function (ev) {
		var input = ev.target;
		var txt = input.value;
		var pos = input.selectionStart;
		if (pos<txt.length) {
			// only allow edition at the end
			txt = txt.substr(0, pos);
			input.value = txt;
			$("#warning").html("Live RNN update: works with edition <u>at the end only</u>");
		} else {
			$("#warning").empty();
		}
		if (iterations.length>txt.length) {
			console.log("truncating iterations");
			iterations = iterations.slice(0, txt.length);
		}
		onInputChars(txt);
	});

	// prevent losing focus on TAB key
	$("textarea").keydown(function(e) {
		if(e.keyCode === 9) { // tab was pressed
			// get caret position/selection
			var start = this.selectionStart;
			var end = this.selectionEnd;

			var $this = $(this);
			var value = $this.val();

			// set textarea value to: text before caret + tab + text after caret
			$this.val(value.substring(0, start)
						+ "\t"
						+ value.substring(end));

			// put caret at right position again (add one for the tab)
			this.selectionStart = this.selectionEnd = start + 1;

			// prevent the focus lose
			e.preventDefault();
		}
	});

	var model, iterations;
	function onModelDataLoaded()  {
		model = model_from_data(data);
		iterations = [ model_initial_state(model.num_layers, model.rnn_size) ];
		console.log("model", model);
		console.log("iterations", iterations);

		$("#info").html('<pre>Network info: \n'
			+ ' num_layers: '+model.num_layers+(model.num_layers==1?' <span style="color: #DC143C;">(only)</span>':'')+'\n'
			+ ' rnn_size: '+model.rnn_size+(model.rnn_size<64?' <span style="color: #DC143C;">(quite small)</span>':'')+'\n' + '</pre>');

		embedding_plot();
	}

	function onInputChars(txt) {
		var last_iter ;
		while ( iterations.length < (txt.length+1) )
			last_iter = onInputCharAppend(txt[iterations.length-1]);
		console.log(last_iter);

		var last_iter = iterations[iterations.length-1];
		display_next_probas(last_iter)
		return last_iter;
	}
	function onInputCharAppend(input_char) {
		var last_iter = model_next_iter(model, iterations, input_char);
		return last_iter;
	}

	function char_label_for_whitespace(c) {
		if (c==" ") c = "[space]";
		if (c=="\n") c = "[newline]";
		if (c=="\r") c = "[linefeed]"
		if (c=="\t") c = "[tab]";
		return c;
	}

	function display_next_probas(last_iter) {
		var probs = last_iter.next_char_probs.slice(0, 7);
		var n = probs.length;
		var html = "";
		for (var i=0; i<n; i++) {
			var c = char_label_for_whitespace(probs[i].c);
			var p = probs[i].prob;
			var pct = Math.round(p*10000)/100;
			var px = Math.round(p*1000);
			html += '<div style="width:'+px+'px; height: 20px; background: lightblue; margin:5px; border-radius: 5px;"><div style="position: absolute;">&nbsp;<em>'+c+'</em> '+pct+'%</div></div>'
		}
		$("#probs").html(html);
	}

	$("#sample").click(ev => sample(1));
	$("#sample_random").click(ev => sample(2));
	$("#sample_many").click(ev => { for (var i=0; i<80;i++) sample(3); });
	function sample(mode) {
		var last_iter = iterations[iterations.length-1];

		var txt = document.getElementById("text").value;
		var last_char = txt[txt.length-1];
		var next_char;
		switch (mode) {
			case 1:
				next_char = last_iter.next_char_probs[0].c ;
				break;
			case 2:
				next_char = pick_in_cumulative(last_iter.next_char_probs);
				break;
			case 3:
				var pick_best = ([ "\n", "\t", "{", "}", "(", ")", "[", "]" ].indexOf(last_char)!=-1);
				next_char  = pick_best
					? last_iter.next_char_probs[0].c
					: pick_in_cumulative(last_iter.next_char_probs);
		}
		txt += next_char;
		document.getElementById("text").value = txt;
		onInputChars(txt);
	}

	function embedding_plot() {
		var i0=0, i1=2;

		var text = model.index_to_text.map(c => "    "+char_label_for_whitespace(c))
			x = model.embedding.map(em => em[i0]),
			y = model.embedding.map(em => em[i1]);

		var filter = (x, i) => model.index_to_text[i].match(/[A-Za-z]/);
		var trace1 = {
			x: x.filter(filter),
			y: y.filter(filter),
			text: text.filter(filter),
			mode: 'markers+text',
			type: 'scatter',
			name: 'Alpha'
			};

		var filter = (x, i) => model.index_to_text[i].match(/[0-9]/);
		var trace2 = {
			x: x.filter(filter),
			y: y.filter(filter),
			text: text.filter(filter),
			mode: 'markers+text',
			type: 'scatter',
			name: 'Numeric'
			};

		var filter = (x, i) => model.index_to_text[i].match(/[^A-Za-z0-9]/);
		var trace3 = {
			x: x.filter(filter),
			y: y.filter(filter),
			text: text.filter(filter),
			mode: 'markers+text',
			type: 'scatter',
			name: 'Special chars'
			};

		var data = [ trace1, trace2, trace3 ];
		Plotly.newPlot('embedding_scatter', data);
	}

});
</script>
</head>

<body>

<h2>A quick dive into recurrent neural network (LSTM).</h2>

<p>LTSM recurrent neural network working at character level trained on Javascript code.
Try typing code in the text area below and see what it predicts as the next character.
Typical things it recognized well : a few keywords <tt>function</tt>, <tt>this</tt> or <tt>return</tt> and vocabulary <tt>length</tt>, <tt>data</tt> or <tt>color</tt>, common structures <tt>for (var i=0; i&lt;n; i++)</tt>, and a bit of indentation (with detection of minified mode).</p>

<div id="info"></div>
<div id="warning" style="color: red;"></div>

<p>Next character prediction:</p>
<div id="probs"></div>
<p><input id="sample" type="button" value="Use next best guess">
<input id="sample_random" type="button" value="Pick one randomly">
<input id="sample_many" type="button" value="Pick many"><br/>
<span style="font-size: x-small;">"Pick randomly" : pick sampling uniformly in the cumulative distribution.</span>
</p>
<textarea id="text" cols="120" rows="8">function f(a, b,</textarea>
<div id="plot"></div>

<h2>A (not so) quick quiz about LSTM</h2>

<p>Screenshot below from Tensorboard : <br/>
This calculation graph is a Tensorflow LTSM cell. It is almost a direct transcription of formulas in Wikipedia article (and other sources).
But what is the <tt>y</tt> additive term highlighted in red ?
</p>

<table><tr><td>
	<p>
	<a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Wikipedia formulas</a>
	and <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">C. Olah graph</a>:
	\[ \begin{align}
	f_t &= \sigma_g(W_{f} x_t + U_{f} h_{t-1} + b_f) \\
	i_t &= \sigma_g(W_{i} x_t + U_{i} h_{t-1} + b_i) \\
	o_t &= \sigma_g(W_{o} x_t + U_{o} h_{t-1} + b_o) \\
	c_t &= f_t \circ c_{t-1} + i_t \circ \sigma_c(W_{c} x_t + U_{c} h_{t-1} + b_c) \\
	h_t &= o_t \circ \sigma_h(c_t)
	\end{align} \]
	</p>
</td><td>
	&nbsp;&nbsp;&nbsp;
</td><td>
	<img src="LSTM2.png" style="width: 200px;">
</td></tr></table>

<p>
<u>Tensorboard version:</u><br/>
<img src="LSTM.png">
</p>

<h2>Embedding plot</h2>

<p>An embedding is a mapping of each <em>of possibly many</em> possible input (char or words) onto a vector of smaller dimension used as neural network input.
It is akin a PCA, where the factors are such that the subsequent classification or regression works best.</p>
</p>

<p>
Embedding of present character level RNN looks like below:<br/>
<div id="embedding_scatter"></div>
</p>
<p>
... which is instructive but nowhere as nice of word level or even image level embedding visualisation:<br/><br/>
<img src="embedding-nearest-points.png" style="max-width: 600px;"></div>
</p>

<div style="height:50px;"></div>
<div style="font-size: smaller;">

	<p>
	Refs:
	<ul>
	<li>Andrej Karpathy <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <br/>
		and <a href="https://gist.github.com/karpathy/d4dee566867f8291f086">Minimal character-level Vanilla RNN model</a> in Python/numpy only.
	<li>Christopher Olah <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTMs</a>
	</ul>
	</p>

	<p>
	Next:
	<ul>
	<li>Display graphically embedding projection.
	<li>Display graphically network internal states
	<li>Generating (and play) abc music notation (see <a href="https://abcjs.net/abcjs-editor.html">interactive editor</a> and many ML blogs). <a href="quicktest2.html">Now done :-).</a>
	<li>Generating drawing. <a href="https://quickdraw.withgoogle.com/data/cat">Pencil</a> or <a href="https://github.com/anishathalye/neural-style">Painting</a>.
	</ul>
	</p>

</div>

</body>

</html>